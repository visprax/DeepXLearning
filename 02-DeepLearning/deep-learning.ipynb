{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3bc99ba-1534-458e-b6d0-5521b72b2ee3",
   "metadata": {},
   "source": [
    "#### Operations\n",
    "\n",
    "An operation in a neural network, in the forward pass, receives an input, does some operation on it, which could depend on some other parameter, like another matrix in a matrix multiplication operation, and outputs an answer. In the backward pass, the operation receives an output gradient, which represents the gradient of the loss function with respect to the output of the operation, which is caluclated from the next operation in the network and passed backward to the current operation node, and calculates the gradient of the loss with resepct to it's input, the input gradient, if the node has parameters, like weights, it will calculate the gradient of the parameters also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3705c561-1f6f-4c9b-8e2d-d1c3d37a6982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Operation:\n",
    "    \"\"\"Base class for a single operation.\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, _input):\n",
    "        self.input_ = input_\n",
    "        self.output  = self._output()\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, output_grad):\n",
    "        assert(self.output.shape == output_grad.shape)\n",
    "        self.input_grad = self._input_grad(output_grad)\n",
    "        assert(self.input_.shape == self.input_grad.shape)\n",
    "        return self.input_grad\n",
    "    \n",
    "    def _output(self):\n",
    "        \"\"\"Helper method to caculate the forward pass of the operation.\"\"\"\n",
    "        raise NotImplementedError(f\"_output helper function not implemented for {self}\")\n",
    "        \n",
    "    def _input_grad(self, output_grad):\n",
    "        \"\"\"Helper method to caculate the backward pass of the operation.\"\"\"\n",
    "        raise NotImplementedError(f\"_input_grad helper function not implemented for {self}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b55026a-c434-4dfc-aa1e-c85885350476",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamOps(Operation):\n",
    "    \"\"\"Operations with parameters need to caculate gradients wrt. param also.\"\"\"\n",
    "    def __init__(self, param):\n",
    "        super().__init__()\n",
    "        self.param = param\n",
    "        \n",
    "    def backward(self, output_grad):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
