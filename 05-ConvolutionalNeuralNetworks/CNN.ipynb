{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb38369e-01a8-4a67-8b88-328a8e89ea43",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks\n",
    "In house price prediction, with a one hidden layer architecture, the networks learns between $\\sqrt{n}$ and $n$ combinations of features. In images, as opposed to say in house price prediction, the most interesting combination of features (pixels) come from pixels that are close to each other, than some random selection of pixels, in here, the order of features matter, as opposed to the problem in house price prediction.\n",
    "\n",
    "For image data, we should have an order of magnitude more combinations of features, and each of these combinations should only be combinations of features from a small rectangle patch in the image. With $n$ input pixels for an input image, each patch goes through a network separately, so the network, in total should learn between $n$ and $n^2$ combinations of feature. Having a network learn combinations of all of the input features, pixels, is inefficient, as it ignores the insight above.\n",
    "\n",
    "In computer vision it is known that if you multiply a certain kernel, here we call it $W$, associated with certain visual patterns, like edges, with certain section of the image, the output of that dot product gives the result of whether there is edges at that location of the image or not, now if we slide this $W$ matrice across the image, taking the dot product, we end up with a new image, called \"feature map\", showing where the pattern defined by $W$ was present at the input image. This is at the core of \"Convolutional Neural Networks\", CNNs.\n",
    "\n",
    "Take this simple example:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "W &= \n",
    "\\begin{bmatrix}\n",
    "w_{11} & w_{12} & w_{13} \\\\\n",
    "w_{21} & w_{22} & w_{23} \\\\\n",
    "w_{31} & w_{32} & w_{33}\n",
    "\\end{bmatrix} \\\\\n",
    "X &= \n",
    "\\begin{bmatrix}\n",
    "x_{11} & x_{12} & x_{13} & x_{14} & x_{15} \\\\\n",
    "x_{21} & x_{22} & x_{23} & x_{24} & x_{25} \\\\\n",
    "x_{31} & x_{32} & x_{33} & x_{34} & x_{35} \\\\\n",
    "x_{41} & x_{42} & x_{43} & x_{44} & x_{45} \\\\\n",
    "x_{51} & x_{52} & x_{53} & x_{54} & x_{55}\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The computed \"feature\" from a local patch of the image, say centered at element $x_{33}$ will be:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "W \\cdot X |_{x_{33}} &= w_{11}x_{22} + w_{12}x_{32} + w_{13}w_{42} \\\\\n",
    "                     &+ w_{21}x_{23} + w_{22}x_{33} + w_{23}x_{43} \\\\\n",
    "                     &+ w_{31}x_{24} + w_{32}x_{34} + w_{33}x_{44}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This value will be treated like any other computed feature from a usuall network, it may have a bias added to it, then probably fed through an activation function, which will represent a neuron or a learned feature, that will get passed to other layers of the network, this way we can define fetures that are functions of small patches of the image. Now if we slide $W$ over the image, taking the dot product $W$ with the pixels centered at each location, we end up with a new image of the same size (depending on edge handling), this is a feature map showing the locations where the \"pattern\" defined by $W$ is existant in each location. This operation is called *Convolution*.\n",
    "\n",
    "#### Multichannel Convolutions\n",
    "\n",
    "For an input image with $n$ pixels, the convolution operation above will create $n$ output features, one for each location in the image. But we can deduce more features from an image by defining multiple weights which define different \"patterns\" in the image, in a convolutional layer we create $f$ sets of $n$ features, each with a randomly initialized weights, whose detection at each location in the input image will be captured in the feature map. These $f$ feature maps will be created via $f$ convolution operations. Each of these $f$ feature maps is called a *channel* of the layer. Each of the $W_i$ weights associated with a particular feature map are called the convolutional *filter* or a *kernel*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c38dd27-dbe2-48ff-b96b-31fe965620e5",
   "metadata": {},
   "source": [
    "#### Deep Convolutional Neural Networks\n",
    "\n",
    "How can we perform the multichannel convolution on an input with multiple channels, for example in a network two convolutional layers? In the first layer of a network with fully connected layers, we have $h_1$ features that are combination of the original input features. In the second layer we have we have $h_2$ combination of previous features, these are features of features, to go from first to second layer we use a $h_1 \\times h_2$ weights, each of the $h_2$ features is a function of each of the $h_1$ features in the previous layer. Same intuition applies in convolutional networks also. \n",
    "\n",
    "We first transform the input image into $m_1$ feature maps using $m_1$ convolutional filters, the ouput of this first convolutional layer represents if each of the $m_1$ visual patters represented by the weights of each of the $m_1$ filters is present at each location of the image. The next layer of a CNN could contain like the MLP, $m_2$ filters which intutively represents patterns of patterns, and whether they are present at that location of the image. A given location in the image on one of the $m_2$ feature maps is a linear combination of convolving $m_1$ different filters over that same location in each of the corresponding $m_1$ feature maps form the prior layer.\n",
    "\n",
    "#### Flatten Layer\n",
    "\n",
    "#### Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1416ffc-c51d-47ae-9b7f-871b69f23659",
   "metadata": {},
   "source": [
    "#### Forward pass\n",
    "\n",
    "*Padding*: To avoid shrinking the ouput as a result of convolution, we pad the input around the edges with zeros, \n",
    "so that the output will be the same shape as input, in general: \n",
    "`P = ((S-1)*W-S+F)/2`, with `F = filter size`, `S = stride`, `W = input size` \n",
    "for our case with a stride of 1: `F-1//2`\n",
    "\n",
    "*Stride*: As pooling layers downsample the image, they reduce the amount of information by a factor of 4, \n",
    "so that an image with just half the resolution fed through the network, these pooling layers have been deprecated  in favor of modifying the stride of the convolution operator. The stride is the amount by which the filter is incrementally slid over the image. For us it was 1. With a stride of 2, the filter would be convolved with every other element of the input image, the output will be half the size of input. This is the same we would get with a size 2 pooling, and thus the same reduction in computation, but without as much loss of information. With pooling of size 2, only one-fourth of the elements in the input have any effect on the output, whereas with a stride of 2, every element of the input has some effect on the output. The use of a stride of greater than 1 is thus significantly more prevalent than pooling for downsampling even in the most advanced CNN architectures of today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd2246b1-0872-488a-9eaf-41494aaf0c82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a9f3f8-e32b-46ab-9b1b-cf5f5c99bf1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1D convolution operator example\n",
    "input_1d = np.array([1, 2, 3, 4, 5])\n",
    "param_1d = np.array([1, 1, 1]) # example filter in 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d124b0ee-09a3-4fab-9645-b46ee17c8f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zero_pad_1d(arr, n):\n",
    "    p = np.array([0] * n)\n",
    "    out = np.concatenate([p, arr, p])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8519d134-258e-4caa-af42-d79943bd17ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 0]\n",
      "[0 1 2 3 4 5 0]\n"
     ]
    }
   ],
   "source": [
    "print(zero_pad_1d(input_1d, 1))\n",
    "print(np.pad(input_1d, 1, constant_values=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb195980-583e-47ee-9147-a1bba53b0e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_1d(arr, param):\n",
    "    n_pad = len(param) // 2\n",
    "    arr_padded = zero_pad_1d(arr, n_pad)\n",
    "    out = np.zeros_like(arr)\n",
    "    for i in range(len(arr)):\n",
    "        for j in range(len(param)):\n",
    "            out[i] += arr_padded[i+j] * param[j]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5766bf8d-12c5-4676-a36b-c402d11e5004",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  6  9 12  9]\n",
      "[ 3  6  9 12  9]\n"
     ]
    }
   ],
   "source": [
    "print(conv_1d(input_1d, param_1d))\n",
    "print(np.convolve(input_1d, param_1d, mode=\"same\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71fc224-05f7-47c1-885c-91d8c40de11f",
   "metadata": {},
   "source": [
    "#### Backward pass\n",
    "\n",
    "We want to compute:\n",
    "- Partial derivative of the loss wrt. each element of the input, `input_1d`, to the convolution operator.\n",
    "- Partial derivative of the loss wrt. each element of the filter, `param_1d`, in the convolution operator.\n",
    "\n",
    "In a simple 1D case, where $X = [x_1, x_2, x_3, x_4, x_5]$ and $W = [w_1, w_2, w_3]$, for the output of convolve is:\n",
    "$$\n",
    "\\begin{align}\n",
    "C = \\textsf{conv}(X, W) = [ \n",
    "x_0w_1 + x_1w_2 + x_2w_3 &= c_1, \\\\\n",
    "x_1w_1 + x_2w_2 + x_3w_3 &= c_2, \\\\\n",
    "x_2w_1 + x_3w_2 + x_4w_3 &= c_3, \\\\\n",
    "x_3w_1 + x_4w_2 + x_5w_3 &= c_4, \\\\\n",
    "x_4w_1 + x_5w_2 + x_6w_3 &= c_5 ]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $x_0$ and $x_6$ are the zero padded elements of the input. If we set the loss to be, $L = \\sum_i c_i$, we can write:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial x_5} &= \n",
    "  \\frac{\\partial L}{\\partial c_4}\\frac{\\partial c_4}{\\partial x_5}\n",
    "+ \\frac{\\partial L}{\\partial c_5}\\frac{\\partial c_5}{\\partial x_5}\n",
    "+ \\frac{\\partial L}{\\partial c_6}\\frac{\\partial c_4}{\\partial x_6} \\\\\n",
    "&= c_4^\\textsf{grad}w_3 + c_5^\\textsf{grad}w_2 + c_6^\\textsf{grad}w_1 \\\\\n",
    "\\frac{\\partial L}{\\partial x_4} &= c_3^\\textsf{grad}w_3 + c_4^\\textsf{grad}w_2 + c_5^\\textsf{grad}w_1 \\\\\n",
    "\\frac{\\partial L}{\\partial x_3} &= c_2^\\textsf{grad}w_3 + c_3^\\textsf{grad}w_2 + c_4^\\textsf{grad}w_1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "When the loss is just a sum, we have $c_i^\\textsf{grad} = 1$, and hence, for example we have $x_5^\\textsf{grad} = w_2 + w_3$, note that $c_6$ is non-existant, we put it there to see the pattern.\n",
    "\n",
    "For the gradient wrt.the weights we can write:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "w_1^{\\textsf{grad}} &= c_1^{\\textsf{grad}}x_0 + c_2^{\\textsf{grad}}x_1 + c_3^{\\textsf{grad}}x_2 + c_4^{\\textsf{grad}}x_3 + c_5^{\\textsf{grad}}x_4 \\\\\n",
    "w_2^{\\textsf{grad}} &= c_1^{\\textsf{grad}}x_1 + c_2^{\\textsf{grad}}x_2 + c_3^{\\textsf{grad}}x_3 + c_4^{\\textsf{grad}}x_4 + c_5^{\\textsf{grad}}x_5 \\\\\n",
    "w_3^{\\textsf{grad}} &= c_1^{\\textsf{grad}}x_2 + c_2^{\\textsf{grad}}x_3 + c_3^{\\textsf{grad}}x_4 + c_4^{\\textsf{grad}}x_5 + c_5^{\\textsf{grad}}x_6\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4660632a-3a67-4b8a-8204-02ec54711a79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for our simple case of L=sum(c_i), the gradient of loss function\n",
    "# wrt. elements of convolution output is 1 with the same shape as input\n",
    "conv = conv_1d(input_1d, input_1d)\n",
    "conv_1d_grad = np.ones_like(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b802ab11-76d5-4d41-bf16-74780ad81a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def input_1d_grads(input_1d, param_1d, out_grad):\n",
    "    n_pad = len(param_1d) // 2\n",
    "    input_grad = np.zeros_like(input_1d)\n",
    "    out_grad_padded = zero_pad_1d(out_grad, n_pad)\n",
    "    for i in range(len(input_1d)):\n",
    "        for j in range(len(param_1d)):\n",
    "            input_grad[i] += out_grad_padded[i+len(param_1d)-j-1] * param_1d[j]\n",
    "    return input_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1420e2ea-d9a9-435f-aa85-cbd6133733a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def param_1d_grads(input_1d, param_1d, out_grad):\n",
    "    n_pad = len(param_1d) // 2\n",
    "    input_1d_padded = zero_pad_1d(input_1d, n_pad)\n",
    "    param_grad = np.zeros_like(param_1d)\n",
    "    for i in range(len(input_1d)):\n",
    "        for j in range(len(param_1d)):\n",
    "            param_grad[j] += out_grad[i] * input_1d_padded[i+j]\n",
    "    return param_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "52beff94-001b-4e02-b014-cdad2586a8f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# increase one element by 1 to see the change in the loss function, \n",
    "# which for our case here, is just the sum of the convolution, \n",
    "# the change in the convolution sum for two inputs, should be equal \n",
    "# to the gradient of the respective element of that input.\n",
    "input_1d_p1 = np.array([1, 2, 3, 4, 6])\n",
    "param_1d_p1 = np.array([2, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2b698c57-2273-4471-a5b5-89b84f27d9c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 3 3 2]\n",
      "2\n",
      "[10 15 14]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(input_1d_grads(input_1d, param_1d, conv_1d_grad))\n",
    "print(np.sum(conv_1d(input_1d_p1, param_1d)) - np.sum(conv_1d(input_1d, param_1d)))\n",
    "\n",
    "print(param_1d_grads(input_1d, param_1d, conv_1d_grad))\n",
    "print(np.sum(conv_1d(input_1d, param_1d_p1)) - np.sum(conv_1d(input_1d, param_1d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bd448fb0-67c6-470e-ae67-e97636f12214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adding the batch dimension\n",
    "input_1d_batch = np.array([[1, 2, 3, 4, 5], \n",
    "                           [10, 11, 2, 3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0969ff16-ed81-4afb-ae51-6d205f04d0c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_1d_batch(input_1d_batch, param_1d):\n",
    "    outs = [conv_1d(obs, param_1d) for obs in input_1d_batch]\n",
    "    out  = np.stack(outs)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9228f872-deb3-4f07-a293-c8b4788dbcd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  6  9 12  9]\n",
      " [21 23 16  9  7]]\n",
      "[[1 1 1 1 1]\n",
      " [1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "conv = conv_1d_batch(input_1d_batch, param_1d)\n",
    "conv_1d_grad_batch = np.ones_like(conv)\n",
    "print(conv)\n",
    "print(conv_1d_grad_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cd72e3e2-3219-4df0-b60d-d582112a5f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def input_1d_grads_batch(input_1d_batch, param_1d, out_grad):\n",
    "    batch_size = len(input_1d_batch)\n",
    "    input_grads = [input_1d_grads(input_1d_batch[i], param_1d, out_grad[i]) for i in range(batch_size)]\n",
    "    out = np.stack(input_grads)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "82a8ad4e-ea81-4278-9d3b-144532d8f769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def param_1d_grads_batch(input_1d_batch, param_1d, out_grad):\n",
    "    param_grad = np.zeros_like(param_1d)\n",
    "    for b in range(input_1d_batch.shape[0]):\n",
    "        n_pad = len(param_1d) // 2\n",
    "        input_1d_padded = zero_pad_1d(input_1d_batch[b], n_pad)\n",
    "        for i in range(input_1d_batch.shape[1]):\n",
    "            for j in range(len(param_1d)):\n",
    "                param_grad[j] += out_grad[b][i] * input_1d_padded[i+j]\n",
    "    return param_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2481208c-f008-4bbf-aa25-294b2d957c25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 3 3 2]\n",
      " [2 3 3 3 2]]\n",
      "[36 45 34]\n"
     ]
    }
   ],
   "source": [
    "print(input_1d_grads_batch(input_1d_batch, param_1d, conv_1d_grad_batch))\n",
    "print(param_1d_grads_batch(input_1d_batch, param_1d, conv_1d_grad_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b7a6c3-c148-4a73-8123-4e3162df33ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
